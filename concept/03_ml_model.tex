\section{Modell} \label{sec:model}

Als Modell soll ein \say{Artificial Neural Network} (ANN) verwendet werden, das mithilfe eines überwachten Lernverfahrens trainiert wird. ANNs besitzen den Vorteil, dass sie sehr gut mit großen Datenmengen umgehen können und nicht auf eine Gleichverteilung der Daten angewiesen sind. Zudem generalisieren sie ein Problem, sodass auch unbekannte Eingaben verarbeitetet werden können. Ein weiterer bedeutender Vorteil von ANNs ist, dass sie sich sehr gut für die Verarbeitung von Bilddaten eignen. \cite{Mahanta2020}

Die aktuell beste Architektur für die Klassifizierung von Bildern stellen \say{Convolutional Neuronal Networks} (CNN) dar. Diese setzen sich grundsätzlich aus zwei Teilen zusammen. Der erste Teil dient zur Merkmalsextraktion und der zweite zur Klassifikation. Nach diesem Prinzip werden zuerst Merkmale, wie Kanten, im gesamten Bild gefunden und anschließend anhand ihrer Komposition klassifiziert. Vertiefende Informationen zu CNNs können unter anderem in \cite{Goodfellow2016} oder in \cite{CS2020} nachgelesen werden.

Für dieses Projekt wird Transfer Learning genutzt. Durch die Verwendung eines vortrainierten CNNs verringert sich die Anzahl der zu lernenden Parameter und die damit verbundene Trainingszeit deutlich. Während des Trainings werden somit nur Gewichte der Klassifikationsschichten gelernt. Optional können auch die Parameter der letzten Schichten des vortrainierten CNNs weiter angepasst werden, um dessen Merkmalsextraktion datensatzspezifischer zu gestalten.

Eine weitere Anpassung, um eine Multi-Label-Klassifikation zu ermöglichen, beinhaltet den Wechsel der finalen Aktivierungsfunktion im Netzwerk von \say{Softmax} zu \say{Sigmoid}. \say{Sigmoid} berechnet jede Aktivierung unabhängig voneinander. Diese Unabhängigkeit der Ergebnisse ist notwendig, da ein Objekt mehreren verschiedenen Klassen zugeordnet werden soll. In dem von uns vorgeschlagenen Netzwerk wird dann aus jeder Kategorie vorerst nur die maximale Aktivierung als Ergebnis verwendet. Für Farben wäre eine spätere Ergänzung denkbar, die es ermöglicht, mehrere Werte zu erkennen, indem alle Aktivierungen über einem bestimmtem Schwellenwert gewählt werden. 

Abschließend werden alle bisher beschriebenen Komponenten in eine Architekturübersicht zusammengefasst (Abbildung \ref{fig:generalArch}). Zuerst werden die Rohbilder durch Augmentation in ihrer Stückzahl erweitert, skaliert und normalisiert. Im Anschluss werden die Bilder durch das vortrainierte CNN zu einen merkmalsangereicherten Volumen transformiert. Dieses Volumen wird dann in ein eindimensionales Array abgeflacht, welches den Input zu mehreren aufeinanderfolgenden Klassifikationsschichten bildet. Die Klassifikationsschichten sind vollvernetzt. Letztlich verarbeitet die Sigmoidfunktion den Output der Klassifikation zu den maximalen Aktivierungen.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{images/general_architecture.png}
	\caption{Architekturübersicht}
	\label{fig:generalArch}
\end{figure}

